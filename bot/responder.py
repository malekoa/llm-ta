# bot/responder.py
import re
from typing import List, Tuple
from openai import OpenAI
from bot.config import Config
from bot.database import Database
from bot.search import search_documents

class Responder:
    HTML_HEADER = f"""
<!-- footer-start -->
<div style="margin-bottom: 20px; padding: 12px; background-color: #e0e0e0; color: #333; font-size: 0.75rem; border-left: 4px solid #555;">
  <p style="margin: 0 0 6px 0;">
    <strong>Disclaimer:</strong> This response was generated by an AI assistant and may contain errors. Please verify all information before relying on it.
  </p>
  <p style="margin: 0;">
    Was this response helpful?
    <a href="{Config.BASE_URL}/feedback?vote=up&message_id=MESSAGE_ID_PLACEHOLDER">üëç Yes</a>
    <a href="{Config.BASE_URL}/feedback?vote=down&message_id=MESSAGE_ID_PLACEHOLDER" style="margin-left: 10px;">üëé No</a>
  </p>
</div>
<!-- footer-end -->
"""

    def __init__(self):
        self.client = OpenAI(api_key=Config.OPENAI_API_KEY)

    def generate(self, subject: str, sender_summary: str, latest_message: str) -> str:
        """
        Generate a Markdown reply using sender summary, latest user message,
        and relevant document chunks.
        """
        # --- Search knowledge base ---
        with Database() as db:
            results = search_documents(db, latest_message, top_k=5)

        if results:
            rag_context = "\n".join(f"- {content}" for _, content, _, _ in results)
            doc_names = sorted({filename for _, _, filename, _ in results})
            docs_line = "Documents consulted: " + ", ".join(doc_names)
        else:
            rag_context = "No relevant context found."
            docs_line = ""

        # --- Compose system prompt ---
        system_prompt = {
            "role": "system",
            "content": (
                "You are Tara, a helpful and friendly teaching assistant.\n"
                "Use the knowledge base when relevant, but avoid hallucinations.\n\n"
                f"Sender summary:\n{sender_summary}\n\n"
                f"Relevant document excerpts:\n{rag_context}\n\n"
                "Respond concisely and naturally. Explain rather than show. Answer without using LaTeX format."
                "Sign off with: Best,  \nTara"
            ),
        }

        # --- Messages: Only latest user message ---
        messages = [
            system_prompt,
            {"role": "user", "content": latest_message}
        ]

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                max_tokens=500,
                temperature=0.7,
            )
            reply = response.choices[0].message.content.strip()
            return reply + ("\n\n---\n" + docs_line if docs_line else "")
        except Exception as e:
            print("Error generating response:", e)
            return "Thank you for your email.\n\nBest,\nAutoTA"

    def remove_previous_footer(self, body: str) -> str:
        pattern = re.compile(r'<!-- footer-start -->.*?<!-- footer-end -->', re.DOTALL)
        return pattern.sub('', body).strip()

    def summarize_sender(self, current_summary: str, new_message: str) -> str:
        system_prompt = {
            "role": "system",
            "content": (
                "You are an assistant that keeps a running summary of each email sender.\n"
                "Update the summary based on the new message while preserving important "
                "information from the existing summary.\n"
                "Only remove information if it is clearly outdated or incorrect.\n"
                "Keep the summary concise (under 200 words) and neutral."
            ),
        }
        messages = [
            system_prompt,
            {"role": "user", "content": f"Current sender summary:\n{current_summary}"},
            {"role": "user", "content": f"New message:\n{new_message}"},
            {"role": "user", "content": "Update the summary."},
        ]
        try:
            response = self.client.chat.completions.create(
                model="gpt-4.1-nano",
                messages=messages,
                max_tokens=200,
                temperature=0.3,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print("Error summarizing sender:", e)
            return current_summary or new_message